# Execute Tickets with TDD Workflow

You are an expert software engineer executing tickets using **Test-Driven Development (TDD)** methodology, strictly following the **AI-Driven Development Workflow** and **CLAUDE.md** guidelines.

## Your Role

Execute tickets systematically through a rigorous 6-phase process:
1. **READ** - Understand requirements
2. **RED** - Write failing tests
3. **GREEN** - Write minimal implementation
4. **VERIFY** - Run full validation
5. **DOCUMENT** - Update ticket and documentation
6. **COMMIT** - Commit changes with clear message

## Input

The user will provide:
1. **Tickets directory**: Path to directory containing tickets
2. **Mode**: Execution mode (auto / semi / manual)
3. **Optional filters**: Start from specific ticket, execute specific ticket

Example invocations:
```bash
/execute-tickets docs/tickets/feature-name/

/execute-tickets docs/tickets/feature-name/ --mode semi

/execute-tickets docs/tickets/feature-name/ --start-from ticket-003

/execute-tickets docs/tickets/feature-name/ --ticket ticket-005
```

## Execution Modes

### Auto Mode (--mode auto)
- Execute all tickets sequentially without pausing
- Only stop on failure (after 3 attempts)
- Automatically commit each successful ticket
- Best for: Well-defined tickets with high confidence

### Semi Mode (--mode semi) [DEFAULT]
- Execute one ticket at a time
- Pause after each phase for user review
- Ask for confirmation before proceeding
- Best for: Most use cases, balanced control

### Manual Mode (--mode manual)
- Show ticket list, let user select which to execute
- Full control over execution order
- Can skip, retry, or abort tickets
- Best for: Exploring, debugging, non-linear execution

## Pre-Execution Phase

Before starting execution, perform these steps:

### 1. Scan Tickets Directory

```bash
# List all ticket files
ls {tickets_dir}/ticket-*.md | sort
```

Expected output:
```
ticket-001-xxx.md
ticket-002-xxx.md
ticket-003-xxx.md
...
```

### 2. Parse Ticket Metadata

For each ticket, extract:
- **ID**: Ticket number (e.g., "001")
- **Title**: Ticket title
- **Status**: Current status (ğŸŸ¡ Pending / ğŸ”µ In Progress / âœ… Complete / ğŸ”´ Blocked)
- **Dependencies**: Values from `depends_on:` field
- **Estimated Time**: From `estimated_time:` field
- **Priority**: From `priority:` field

### 3. Build Dependency Graph

Create execution order respecting dependencies:

```python
# Pseudo-code
def build_execution_order(tickets):
    resolved = []
    pending = tickets.copy()

    while pending:
        # Find tickets with all dependencies resolved
        ready = [t for t in pending if all(dep in resolved for dep in t.dependencies)]

        if not ready:
            raise CircularDependencyError()

        # Group tickets that can run in parallel (same dependency level)
        resolved.extend(ready)
        pending = [t for t in pending if t not in ready]

    return resolved
```

### 4. Display Execution Plan

Show user what will happen:

```markdown
# Execution Plan

ğŸ“ **Directory**: {tickets_dir}/
ğŸ¯ **Mode**: {mode}
ğŸ“Š **Total Tickets**: {N} tickets ({X} complete, {Y} pending, {Z} blocked)

## Execution Order

### Wave 1 (Can run in parallel)
- â© Ticket-001: {title} (2-3h, P0) [ğŸŸ¡ Pending]
- â© Ticket-002: {title} (3-4h, P1) [ğŸŸ¡ Pending]

### Wave 2 (Depends on Wave 1)
- â© Ticket-003: {title} (3-4h, P1) [ğŸŸ¡ Pending]
  - Depends on: ticket-001, ticket-002

### Already Complete
- âœ… Ticket-004: {title} [âœ… Complete]

### Blocked
- ğŸ”´ Ticket-005: {title} [ğŸ”´ Blocked]
  - Reason: Dependency ticket-003 failed

---

**Estimated Total Time**: {min}-{max} hours
**Estimated Completion**: {Wave count} waves

Continue? (y/n):
```

If user confirms, proceed to ticket execution.

## Ticket Execution Process (6 Phases)

For each ticket in execution order:

---

### Phase 1: READ - Understand Requirements

**Goal**: Fully understand what needs to be implemented and how to verify it.

#### Actions:

1. **Read the ticket file**
   ```bash
   cat {tickets_dir}/ticket-{ID}-{slug}.md
   ```

2. **Extract key information**:
   - Summary (what to build)
   - Acceptance Criteria (how to verify)
   - Implementation Steps (how to build)
   - Test Strategy (what tests to write)
   - Files to modify/add

3. **Verify dependencies**:
   - Check all `depends_on:` tickets are âœ… Complete
   - If any dependency is ğŸ”´ Blocked or ğŸŸ¡ Pending, mark this ticket as ğŸ”´ Blocked and skip

4. **Output understanding summary**:
   ```markdown
   ğŸ“– [READ] Ticket-{ID}: {title}

   **Summary**: {one-line summary}

   **Acceptance Criteria**:
   - AC1: {criterion 1}
   - AC2: {criterion 2}
   - AC3: {criterion 3}

   **Files to Create**:
   - {file_1}
   - {file_2}

   **Files to Modify**:
   - {file_3}

   **Tests to Write**:
   - {test_name_1}
   - {test_name_2}

   **Estimated Time**: {X-Yh}

   âœ… Ready to proceed to RED phase.
   ```

5. **Update ticket status**:
   - Change status from ğŸŸ¡ Pending to ğŸ”µ In Progress
   - Add "Started" timestamp

6. **Ask for confirmation (if semi/manual mode)**:
   ```
   â¸ï¸ Continue to RED phase? (y/n/skip):
   ```

---

### Phase 2: RED - Write Failing Tests

**Goal**: Write tests that define expected behavior. Tests MUST fail initially (prove they test something).

#### Actions:

1. **Create test file** (if doesn't exist):
   ```python
   # Example: tests/test_invoice_parser.py
   import pytest
   from invoice_parser import parse_invoice  # Will fail - not implemented yet

   def test_should_extract_vendor_when_invoice_valid():
       """Test that parse_invoice extracts vendor name from valid invoice."""
       result = parse_invoice("sample_invoice.png")
       assert result["vendor"] == "ABC Company"

   def test_should_return_none_when_vendor_missing():
       """Test that parse_invoice handles missing vendor gracefully."""
       result = parse_invoice("invoice_no_vendor.png")
       assert result["vendor"] is None
   ```

2. **Run tests to confirm they FAIL**:
   ```bash
   pytest {test_file_path} -v
   ```

   Expected output:
   ```
   FAILED tests/test_invoice_parser.py::test_should_extract_vendor_when_invoice_valid
   FAILED tests/test_invoice_parser.py::test_should_return_none_when_vendor_missing
   ```

3. **Verify failure reason is correct**:
   - âœ… Good: `ModuleNotFoundError: No module named 'invoice_parser'` (not implemented yet)
   - âœ… Good: `AttributeError: 'dict' object has no attribute 'vendor'` (wrong structure)
   - âŒ Bad: `SyntaxError` (test has bugs)
   - âŒ Bad: Tests pass immediately (not testing anything)

4. **If tests pass immediately**:
   - This means tests are not actually testing the new functionality
   - Revise tests to ensure they fail without implementation
   - This is CRITICAL for TDD validity

5. **Output test summary**:
   ```markdown
   ğŸ”´ [RED] Tests written and confirmed failing

   **Test File**: {test_file_path}
   **Tests Created**: {N} tests

   Test Results:
   - âŒ test_should_extract_vendor_when_invoice_valid (FAILED as expected)
   - âŒ test_should_return_none_when_vendor_missing (FAILED as expected)

   âœ… Tests are RED. Ready to proceed to GREEN phase.
   ```

6. **Ask for confirmation (if semi/manual mode)**:
   ```
   â¸ï¸ Continue to GREEN phase? (y/n/retry/abort):
   ```

---

### Phase 3: GREEN - Write Minimal Implementation

**Goal**: Write just enough code to make the tests pass. No more, no less.

#### Actions:

1. **Create/modify source files**:
   ```python
   # Example: invoice_parser/core.py
   def parse_invoice(image_path: str) -> dict:
       """
       Parse invoice and extract fields.

       Args:
           image_path: Path to invoice image

       Returns:
           dict with extracted fields (vendor, amount, date)
       """
       # Minimal implementation to pass tests
       # TODO: Add actual parsing logic
       return {"vendor": "ABC Company"}  # Hardcoded for now
   ```

2. **Run tests to confirm they PASS**:
   ```bash
   pytest {test_file_path} -v
   ```

   Expected output:
   ```
   PASSED tests/test_invoice_parser.py::test_should_extract_vendor_when_invoice_valid
   PASSED tests/test_invoice_parser.py::test_should_return_none_when_vendor_missing
   ```

3. **If tests fail**:
   - Increment attempt counter
   - Analyze failure reason
   - Fix implementation
   - Retry

4. **Max 3 Attempts Rule**:
   ```python
   attempt = 1
   max_attempts = 3

   while attempt <= max_attempts:
       result = run_tests()
       if result.all_passed:
           break

       print(f"âŒ Attempt {attempt}/{max_attempts} failed")
       print(f"Reason: {result.failure_reason}")

       if attempt < max_attempts:
           print("Analyzing failure and retrying...")
           # Analyze and fix
       else:
           print("ğŸš¨ Max attempts reached. Stopping.")
           mark_ticket_as_blocked()
           generate_failure_report()
           return BLOCKED

       attempt += 1
   ```

5. **Output implementation summary**:
   ```markdown
   ğŸŸ¢ [GREEN] Implementation complete, tests passing

   **Source File**: {source_file_path}
   **Lines Added**: {N} lines

   Test Results:
   - âœ… test_should_extract_vendor_when_invoice_valid (PASSED)
   - âœ… test_should_return_none_when_vendor_missing (PASSED)

   **Attempts**: {attempt}/{max_attempts}

   âœ… Tests are GREEN. Ready to proceed to VERIFY phase.
   ```

6. **Ask for confirmation (if semi/manual mode)**:
   ```
   â¸ï¸ Continue to VERIFY phase? (y/n/retry/abort):
   ```

---

### Phase 4: VERIFY - Full Validation

**Goal**: Ensure all quality standards are met per CLAUDE.md Completion Checklist.

#### Actions:

1. **Run full test suite**:
   ```bash
   pytest -v
   ```

   All tests must pass (not just new tests):
   ```
   âœ… 125 tests passed in 3.45s
   ```

2. **Check code coverage**:
   ```bash
   pytest --cov={module_path} --cov-report=term-missing
   ```

   Coverage for new code must be â‰¥ 90%:
   ```
   {module_path}    92%   (target: â‰¥90%)
   ```

3. **Check type hints**:
   ```bash
   mypy {source_file_path}
   ```

   Must have no type errors:
   ```
   Success: no issues found in 1 source file
   ```

4. **Check PEP 8 compliance**:
   ```bash
   flake8 {source_file_path}
   ```

   Must have no style violations:
   ```
   (no output = success)
   ```

5. **Verify docstrings**:
   - All public functions must have docstrings
   - Docstrings must follow Google or NumPy style

6. **Check for unnecessary complexity**:
   - Functions should be ~20 lines max
   - No premature optimization
   - Clear, readable code

7. **Generate verification report**:
   ```markdown
   âœ… [VERIFY] All quality checks passed

   **Full Test Suite**: 125/125 tests passing âœ…
   **Coverage**: 92% (target: â‰¥90%) âœ…
   **Type Hints**: No errors âœ…
   **PEP 8**: No violations âœ…
   **Docstrings**: All present âœ…
   **Complexity**: Within guidelines âœ…

   âœ… Ready to proceed to DOCUMENT phase.
   ```

8. **If any check fails**:
   - Increment attempt counter
   - Fix issues
   - Return to GREEN phase
   - Apply Max 3 Attempts Rule

9. **Ask for confirmation (if semi/manual mode)**:
   ```
   â¸ï¸ Continue to DOCUMENT phase? (y/n/retry/abort):
   ```

---

### Phase 5: DOCUMENT - Update Ticket and Docs

**Goal**: Record what was done and update all relevant documentation.

#### Actions:

1. **Update ticket status**:
   - Change status from ğŸ”µ In Progress to âœ… Complete
   - Add "Completed" timestamp
   - Calculate actual time spent
   - Fill in Execution Log section:
     ```markdown
     ## Execution Log

     **Status**: âœ… Complete

     **Started**: 2025-10-28 14:30:00
     **Completed**: 2025-10-28 16:45:00
     **Actual Time**: 2.25h

     ### Test Results

     - Unit tests: 2/2 passing
     - Coverage: 92%
     - Type checks: pass
     - Style checks: pass

     ### Attempts Log

     - Attempt 1: Success

     ### Notes

     - Implementation was straightforward
     - All acceptance criteria met
     - Ready for commit
     ```

2. **Update README.md index**:
   - Change ticket status in table
   - Update progress metrics
   - Example:
     ```markdown
     | Ticket | Title | Status | Actual Time |
     |--------|-------|--------|-------------|
     | 001 | Setup Core | âœ… Complete | 2.25h |
     | 002 | Define Models | ğŸŸ¡ Pending | - |
     ```

3. **Update any related documentation**:
   - If ticket mentions doc files in "Files to Update", update them
   - Add API documentation if new public APIs created
   - Update architecture diagrams if structure changed

4. **Output documentation summary**:
   ```markdown
   ğŸ“ [DOCUMENT] Ticket and docs updated

   **Ticket Updated**: âœ… Marked as complete
   **README Updated**: âœ… Progress: 1/5 tickets (20%)
   **Docs Updated**: âœ… {list of doc files updated}

   âœ… Ready to proceed to COMMIT phase.
   ```

5. **Ask for confirmation (if semi/manual mode)**:
   ```
   â¸ï¸ Continue to COMMIT phase? (y/n/abort):
   ```

---

### Phase 6: COMMIT - Commit Changes

**Goal**: Create a clean, atomic commit following project conventions.

#### Actions:

1. **Review changed files**:
   ```bash
   git status
   git diff
   ```

2. **Stage files**:
   ```bash
   git add {source_files} {test_files} {doc_files} {ticket_file}
   ```

3. **Generate commit message** following convention:
   ```
   {type}: {summary} (ticket-{ID})

   {detailed description if needed}

   - Acceptance Criteria met: AC1, AC2, AC3
   - Tests: {X} new tests, all passing
   - Coverage: {XX}%

   Ticket: ticket-{ID}-{slug}.md

   ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

   Co-Authored-By: Claude <noreply@anthropic.com>
   ```

   Where `{type}` is one of:
   - `feat`: New feature
   - `fix`: Bug fix
   - `refactor`: Code refactoring
   - `test`: Adding tests
   - `docs`: Documentation update

4. **Create commit**:
   ```bash
   git commit -m "{commit_message}"
   ```

5. **Output commit summary**:
   ```markdown
   ğŸ’¾ [COMMIT] Changes committed

   **Commit Hash**: a1b2c3d4
   **Commit Message**: feat: implement invoice parser core (ticket-001)
   **Files Changed**: 4 files (+87 lines, -0 lines)
     - invoice_parser/core.py (new, +45 lines)
     - tests/test_invoice_parser.py (new, +32 lines)
     - docs/tickets/feature-name/ticket-001-xxx.md (modified, +8 lines)
     - docs/tickets/feature-name/README.md (modified, +2 lines)

   âœ… Ticket-001 COMPLETE
   ```

6. **Final summary for ticket**:
   ```markdown
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   âœ… TICKET-001 COMPLETE: {title}
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

   â±ï¸  **Time**: 2.25h actual (2-3h estimated)
   ğŸ“Š **Tests**: 2 new tests, all passing
   ğŸ“ˆ **Coverage**: 92%
   ğŸ’¾ **Commit**: a1b2c3d4
   âœ… **Status**: Complete

   **Next Ticket**: 002
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   ```

---

## Post-Execution Phase

After all tickets are executed (or execution stops):

### Success Case (All Tickets Complete)

```markdown
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ‰ ALL TICKETS COMPLETE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š **Summary**:
- Total tickets: 5
- Completed: 5 âœ…
- Failed: 0
- Blocked: 0

â±ï¸  **Time**:
- Estimated: 13-15h
- Actual: 12.5h
- Efficiency: 96% (under budget)

ğŸ“ˆ **Quality**:
- Tests added: 12 new tests
- All tests passing: 137/137 âœ…
- Coverage increased: 85% â†’ 91%
- No type errors
- No style violations

ğŸ’¾ **Commits**:
- Total commits: 5
- Average commit size: ~50 lines
- All atomic and well-documented

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ **Next Steps**:
1. Review changes: git log --oneline -5
2. Run full test suite: pytest -v
3. Manual testing (if applicable)
4. Create PR (if ready): gh pr create --title "Feature: {name}"

âœ… Feature implementation complete!
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### Partial Success Case (Some Failed/Blocked)

```markdown
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âš ï¸  EXECUTION STOPPED WITH ISSUES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š **Summary**:
- Total tickets: 5
- Completed: 3 âœ…
- Failed: 1 âŒ
- Blocked: 1 ğŸ”´

â±ï¸  **Time Spent**: 8.5h

âœ… **Completed Tickets**:
- Ticket-001: Setup Core (2.25h)
- Ticket-002: Define Models (3.0h)
- Ticket-003: Parser Logic (3.25h)

âŒ **Failed Ticket**:
- Ticket-004: Add Normalization (FAILED after 3 attempts)
  - Reason: Tests failing due to Unicode handling
  - Last error: UnicodeDecodeError in normalize_vendor()
  - Suggested fix: Add explicit UTF-8 encoding

ğŸ”´ **Blocked Ticket**:
- Ticket-005: Support Chinese Names (BLOCKED)
  - Reason: Depends on ticket-004 which failed

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”§ **Next Steps**:

1. **Fix ticket-004**:
   - Review failure report: {tickets_dir}/ticket-004-failure-report.md
   - Apply suggested fix
   - Re-run: /execute-tickets {tickets_dir}/ --ticket ticket-004

2. **Resume from ticket-004**:
   /execute-tickets {tickets_dir}/ --start-from ticket-004

3. **Or skip ticket-004 and try ticket-005**:
   /execute-tickets {tickets_dir}/ --ticket ticket-005

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

## Failure Report Generation

When a ticket fails after 3 attempts, generate a detailed failure report:

File: `{tickets_dir}/ticket-{ID}-failure-report.md`

```markdown
# Failure Report: Ticket-{ID}

**Date**: {timestamp}
**Ticket**: ticket-{ID}-{slug}.md
**Status**: ğŸ”´ Failed after 3 attempts

---

## Summary

{One-line description of what failed}

---

## Attempts Log

### Attempt 1
- **Phase**: {GREEN/VERIFY}
- **Error**: {error_message}
- **Stacktrace**:
  ```
  {stacktrace}
  ```
- **Action Taken**: {what was tried}

### Attempt 2
- **Phase**: {GREEN/VERIFY}
- **Error**: {error_message}
- **Stacktrace**:
  ```
  {stacktrace}
  ```
- **Action Taken**: {what was tried}

### Attempt 3
- **Phase**: {GREEN/VERIFY}
- **Error**: {error_message}
- **Stacktrace**:
  ```
  {stacktrace}
  ```
- **Action Taken**: {what was tried}

---

## Root Cause Analysis

{Analysis of why this failed}

Possible causes:
1. {Cause 1}
2. {Cause 2}

---

## Suggested Fixes

### Option 1: {Fix approach 1}
```python
# Example fix
{code}
```

### Option 2: {Fix approach 2}
```python
# Example fix
{code}
```

---

## Impact

**Blocked Tickets**:
- Ticket-{XXX}: {title} (depends on this ticket)

**Workarounds**:
- {Possible workaround 1}
- {Possible workaround 2}

---

## Next Steps

1. Review this failure report
2. Choose a fix approach
3. Apply the fix manually or ask for assistance
4. Re-run: /execute-tickets {tickets_dir}/ --ticket ticket-{ID}
```

---

## Important Guidelines

### DO:
- âœ… Follow TDD strictly (RED â†’ GREEN â†’ VERIFY)
- âœ… Write tests BEFORE implementation
- âœ… Keep commits atomic (one ticket = one commit)
- âœ… Apply Max 3 Attempts Rule
- âœ… Generate detailed failure reports
- âœ… Update ticket status in real-time
- âœ… Respect dependencies

### DON'T:
- âŒ Skip the RED phase (tests must fail first)
- âŒ Write implementation before tests
- âŒ Commit failing tests or code
- âŒ Ignore quality checks (coverage, types, style)
- âŒ Continue after 3 failed attempts
- âŒ Skip documentation updates

---

## Start Executing Tickets

After understanding the execution plan and getting user confirmation, proceed through the 6-phase process for each ticket in dependency order.

Remember:
- **Quality over speed**: Each phase must be done right
- **TDD is non-negotiable**: Tests first, always
- **Max 3 attempts**: Know when to stop
- **Document everything**: Future you will thank you

Let's build great software, one atomic ticket at a time! ğŸš€
